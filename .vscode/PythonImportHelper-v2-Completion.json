[
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "xgboost",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "xgboost",
        "description": "xgboost",
        "detail": "xgboost",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "seaborn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "seaborn",
        "description": "seaborn",
        "detail": "seaborn",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "GridSearchCV",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "GridSearchCV",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "GridSearchCV",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "mean_squared_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "r2_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "mean_squared_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "r2_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "mean_squared_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "r2_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "r2_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "mean_squared_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "glob",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "glob",
        "description": "glob",
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "folium",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "folium",
        "description": "folium",
        "detail": "folium",
        "documentation": {}
    },
    {
        "label": "MarkerCluster",
        "importPath": "folium.plugins",
        "description": "folium.plugins",
        "isExtraImport": true,
        "detail": "folium.plugins",
        "documentation": {}
    },
    {
        "label": "RandomForestRegressor",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "files",
        "kind": 5,
        "importPath": "Final GB Model",
        "description": "Final GB Model",
        "peekOfCode": "files = {\n    \"2015\": \"2015_CostReport_cleaned.csv\",\n    \"2016\": \"2016_CostReport_cleaned.csv\",\n    \"2017\": \"2017_CostReport_cleaned.csv\",\n    \"2018\": \"2018_CostReport_cleaned.csv\",\n    \"2019\": \"2019_CostReport_cleaned.csv\",\n    \"2020\": \"2020_CostReport_cleaned.csv\",\n    \"2021\": \"2021_CostReport_cleaned.csv\"\n}\n# List to store dataframes for each year",
        "detail": "Final GB Model",
        "documentation": {}
    },
    {
        "label": "all_dataframes",
        "kind": 5,
        "importPath": "Final GB Model",
        "description": "Final GB Model",
        "peekOfCode": "all_dataframes = []\n# Loop through each file, read it, add a 'Year' column, and append to the list\nfor year, path in files.items():\n    df = pd.read_csv(path, low_memory=False)  # read CSV file\n    df['Year'] = int(year)  # add a 'Year' column for reference\n    all_dataframes.append(df)  # append the dataframe to the list\n# Combine all yearly dataframes into one single dataframe\nmerged_df = pd.concat(all_dataframes, ignore_index=True)\n# Selecting relevant features for the model (commented out features are excluded)\nX = merged_df[[",
        "detail": "Final GB Model",
        "documentation": {}
    },
    {
        "label": "merged_df",
        "kind": 5,
        "importPath": "Final GB Model",
        "description": "Final GB Model",
        "peekOfCode": "merged_df = pd.concat(all_dataframes, ignore_index=True)\n# Selecting relevant features for the model (commented out features are excluded)\nX = merged_df[[\n    # 'cash_on_hand_and_in_banks',\n    # 'overhead_non_salary_costs',\n    # 'total_fund_balances',\n    'gross_revenue',\n    'total_income',\n    'total_costs',\n    'total_current_assets',",
        "detail": "Final GB Model",
        "documentation": {}
    },
    {
        "label": "X",
        "kind": 5,
        "importPath": "Final GB Model",
        "description": "Final GB Model",
        "peekOfCode": "X = merged_df[[\n    # 'cash_on_hand_and_in_banks',\n    # 'overhead_non_salary_costs',\n    # 'total_fund_balances',\n    'gross_revenue',\n    'total_income',\n    'total_costs',\n    'total_current_assets',\n    'total_current_liabilities',\n    'total_liabilities',",
        "detail": "Final GB Model",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": "Final GB Model",
        "description": "Final GB Model",
        "peekOfCode": "y = merged_df['net_income']\n# Split data into training and testing sets (80% train, 20% test)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Standardize the features (zero mean, unit variance)\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)  # fit on training data\nX_test = scaler.transform(X_test)  # transform test data using the same scaler\n# Define parameter grid for hyperparameter tuning\nparam_grid = {\n    'n_estimators': [100, 200, 300],  # number of trees",
        "detail": "Final GB Model",
        "documentation": {}
    },
    {
        "label": "scaler",
        "kind": 5,
        "importPath": "Final GB Model",
        "description": "Final GB Model",
        "peekOfCode": "scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)  # fit on training data\nX_test = scaler.transform(X_test)  # transform test data using the same scaler\n# Define parameter grid for hyperparameter tuning\nparam_grid = {\n    'n_estimators': [100, 200, 300],  # number of trees\n    'learning_rate': [0.05, 0.1, 0.2],  # step size shrinkage\n    'max_depth': [3, 4, 5]  # maximum depth of trees\n}\n# Use GridSearchCV to find the best combination of parameters",
        "detail": "Final GB Model",
        "documentation": {}
    },
    {
        "label": "X_train",
        "kind": 5,
        "importPath": "Final GB Model",
        "description": "Final GB Model",
        "peekOfCode": "X_train = scaler.fit_transform(X_train)  # fit on training data\nX_test = scaler.transform(X_test)  # transform test data using the same scaler\n# Define parameter grid for hyperparameter tuning\nparam_grid = {\n    'n_estimators': [100, 200, 300],  # number of trees\n    'learning_rate': [0.05, 0.1, 0.2],  # step size shrinkage\n    'max_depth': [3, 4, 5]  # maximum depth of trees\n}\n# Use GridSearchCV to find the best combination of parameters\ngrid_search = GridSearchCV(xgb.XGBRegressor(random_state=42), param_grid, cv=5, scoring='r2')",
        "detail": "Final GB Model",
        "documentation": {}
    },
    {
        "label": "X_test",
        "kind": 5,
        "importPath": "Final GB Model",
        "description": "Final GB Model",
        "peekOfCode": "X_test = scaler.transform(X_test)  # transform test data using the same scaler\n# Define parameter grid for hyperparameter tuning\nparam_grid = {\n    'n_estimators': [100, 200, 300],  # number of trees\n    'learning_rate': [0.05, 0.1, 0.2],  # step size shrinkage\n    'max_depth': [3, 4, 5]  # maximum depth of trees\n}\n# Use GridSearchCV to find the best combination of parameters\ngrid_search = GridSearchCV(xgb.XGBRegressor(random_state=42), param_grid, cv=5, scoring='r2')\ngrid_search.fit(X_train, y_train)  # train with cross-validation",
        "detail": "Final GB Model",
        "documentation": {}
    },
    {
        "label": "param_grid",
        "kind": 5,
        "importPath": "Final GB Model",
        "description": "Final GB Model",
        "peekOfCode": "param_grid = {\n    'n_estimators': [100, 200, 300],  # number of trees\n    'learning_rate': [0.05, 0.1, 0.2],  # step size shrinkage\n    'max_depth': [3, 4, 5]  # maximum depth of trees\n}\n# Use GridSearchCV to find the best combination of parameters\ngrid_search = GridSearchCV(xgb.XGBRegressor(random_state=42), param_grid, cv=5, scoring='r2')\ngrid_search.fit(X_train, y_train)  # train with cross-validation\n# Retrieve and print the best hyperparameters found\nbest_params = grid_search.best_params_",
        "detail": "Final GB Model",
        "documentation": {}
    },
    {
        "label": "grid_search",
        "kind": 5,
        "importPath": "Final GB Model",
        "description": "Final GB Model",
        "peekOfCode": "grid_search = GridSearchCV(xgb.XGBRegressor(random_state=42), param_grid, cv=5, scoring='r2')\ngrid_search.fit(X_train, y_train)  # train with cross-validation\n# Retrieve and print the best hyperparameters found\nbest_params = grid_search.best_params_\nprint(\"Best Parameters:\", best_params)\n# Train final model using the best parameters from GridSearch\nmodel = xgb.XGBRegressor(**best_params, random_state=42)\nmodel.fit(X_train, y_train)\n# Make predictions on the test set\ny_pred = model.predict(X_test)",
        "detail": "Final GB Model",
        "documentation": {}
    },
    {
        "label": "best_params",
        "kind": 5,
        "importPath": "Final GB Model",
        "description": "Final GB Model",
        "peekOfCode": "best_params = grid_search.best_params_\nprint(\"Best Parameters:\", best_params)\n# Train final model using the best parameters from GridSearch\nmodel = xgb.XGBRegressor(**best_params, random_state=42)\nmodel.fit(X_train, y_train)\n# Make predictions on the test set\ny_pred = model.predict(X_test)\n# Evaluate the model using common regression metrics\nmse = mean_squared_error(y_test, y_pred)  # mean squared error\nr2 = r2_score(y_test, y_pred)  # R-squared score",
        "detail": "Final GB Model",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "Final GB Model",
        "description": "Final GB Model",
        "peekOfCode": "model = xgb.XGBRegressor(**best_params, random_state=42)\nmodel.fit(X_train, y_train)\n# Make predictions on the test set\ny_pred = model.predict(X_test)\n# Evaluate the model using common regression metrics\nmse = mean_squared_error(y_test, y_pred)  # mean squared error\nr2 = r2_score(y_test, y_pred)  # R-squared score\nrmse = np.sqrt(mse)  # root mean squared error\n# Print evaluation results\nprint(f\"\\nFinal RMSE on Test Set: {rmse:.2f}\")",
        "detail": "Final GB Model",
        "documentation": {}
    },
    {
        "label": "y_pred",
        "kind": 5,
        "importPath": "Final GB Model",
        "description": "Final GB Model",
        "peekOfCode": "y_pred = model.predict(X_test)\n# Evaluate the model using common regression metrics\nmse = mean_squared_error(y_test, y_pred)  # mean squared error\nr2 = r2_score(y_test, y_pred)  # R-squared score\nrmse = np.sqrt(mse)  # root mean squared error\n# Print evaluation results\nprint(f\"\\nFinal RMSE on Test Set: {rmse:.2f}\")\nprint(f\"Mean Squared Error: {mse:.4f}\")\nprint(f\"R^2 Score: {r2:.4f}\")\n# # Feature importance visualization (currently commented out)",
        "detail": "Final GB Model",
        "documentation": {}
    },
    {
        "label": "mse",
        "kind": 5,
        "importPath": "Final GB Model",
        "description": "Final GB Model",
        "peekOfCode": "mse = mean_squared_error(y_test, y_pred)  # mean squared error\nr2 = r2_score(y_test, y_pred)  # R-squared score\nrmse = np.sqrt(mse)  # root mean squared error\n# Print evaluation results\nprint(f\"\\nFinal RMSE on Test Set: {rmse:.2f}\")\nprint(f\"Mean Squared Error: {mse:.4f}\")\nprint(f\"R^2 Score: {r2:.4f}\")\n# # Feature importance visualization (currently commented out)\n# feature_importance = model.feature_importances_\n# sorted_idx = np.argsort(feature_importance)[::-1]",
        "detail": "Final GB Model",
        "documentation": {}
    },
    {
        "label": "r2",
        "kind": 5,
        "importPath": "Final GB Model",
        "description": "Final GB Model",
        "peekOfCode": "r2 = r2_score(y_test, y_pred)  # R-squared score\nrmse = np.sqrt(mse)  # root mean squared error\n# Print evaluation results\nprint(f\"\\nFinal RMSE on Test Set: {rmse:.2f}\")\nprint(f\"Mean Squared Error: {mse:.4f}\")\nprint(f\"R^2 Score: {r2:.4f}\")\n# # Feature importance visualization (currently commented out)\n# feature_importance = model.feature_importances_\n# sorted_idx = np.argsort(feature_importance)[::-1]\n# plt.figure(figsize=(10, 6))",
        "detail": "Final GB Model",
        "documentation": {}
    },
    {
        "label": "rmse",
        "kind": 5,
        "importPath": "Final GB Model",
        "description": "Final GB Model",
        "peekOfCode": "rmse = np.sqrt(mse)  # root mean squared error\n# Print evaluation results\nprint(f\"\\nFinal RMSE on Test Set: {rmse:.2f}\")\nprint(f\"Mean Squared Error: {mse:.4f}\")\nprint(f\"R^2 Score: {r2:.4f}\")\n# # Feature importance visualization (currently commented out)\n# feature_importance = model.feature_importances_\n# sorted_idx = np.argsort(feature_importance)[::-1]\n# plt.figure(figsize=(10, 6))\n# plt.barh(np.array(X.columns)[sorted_idx], feature_importance[sorted_idx])",
        "detail": "Final GB Model",
        "documentation": {}
    },
    {
        "label": "load_address_info",
        "kind": 2,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "def load_address_info(filepath):\n    ## reads file and loads it into a DataFrame\n    df = pd.read_csv(filepath, encoding='ISO-8859-1', low_memory=False) \n    ## Standardize column names\n    df.columns = df.columns.str.strip().str.lower()\n    ### Extract year from filename\n    year = os.path.basename(filepath).split(\"_\")[1]\n    df['year'] = int(year)\n    ### Check for required columns\n    required_cols = ['address', 'city', 'state', 'zip', 'year']",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "merged_df",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "merged_df = pd.concat(all_dataframes, ignore_index=True)\n# Show the shape or a preview\nprint(\"Merged DataFrame shape:\", merged_df.shape)\nprint(merged_df.head())\n# Check the columns of the merged DataFrame\nprint(merged_df.columns)\n# # Get basic statistics\nprint(merged_df.describe())\n# Yearly average net income\n# # print(merged_df.groupby(\"Year\")['Net_Income'].mean())",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "files",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "files = glob.glob(\"QualityMsrMDS_20*_Cleaned.csv\")\n## Function to load address info\ndef load_address_info(filepath):\n    ## reads file and loads it into a DataFrame\n    df = pd.read_csv(filepath, encoding='ISO-8859-1', low_memory=False) \n    ## Standardize column names\n    df.columns = df.columns.str.strip().str.lower()\n    ### Extract year from filename\n    year = os.path.basename(filepath).split(\"_\")[1]\n    df['year'] = int(year)",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "address_df",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "address_df = pd.concat([load_address_info(f) for f in files], ignore_index=True)\naddress_df.drop_duplicates(subset=['address', 'city', 'state', 'zip'], inplace=True)\n# Load ZIP code coordinates\nzip_latlng_df = pd.read_csv('uszips.csv')\nzip_latlng_df['zip'] = zip_latlng_df['zip'].astype(str).str.zfill(5)\naddress_df['zip'] = address_df['zip'].astype(str).str.zfill(5)\n# Merge dataframes\n# Merge address info with ZIP coordinates\nmerged_df = pd.merge(\n    address_df,",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "zip_latlng_df",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "zip_latlng_df = pd.read_csv('uszips.csv')\nzip_latlng_df['zip'] = zip_latlng_df['zip'].astype(str).str.zfill(5)\naddress_df['zip'] = address_df['zip'].astype(str).str.zfill(5)\n# Merge dataframes\n# Merge address info with ZIP coordinates\nmerged_df = pd.merge(\n    address_df,\n    zip_latlng_df[['zip', 'lat', 'lng']],\n    how='inner',\n    on='zip'",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "zip_latlng_df['zip']",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "zip_latlng_df['zip'] = zip_latlng_df['zip'].astype(str).str.zfill(5)\naddress_df['zip'] = address_df['zip'].astype(str).str.zfill(5)\n# Merge dataframes\n# Merge address info with ZIP coordinates\nmerged_df = pd.merge(\n    address_df,\n    zip_latlng_df[['zip', 'lat', 'lng']],\n    how='inner',\n    on='zip'\n)",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "address_df['zip']",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "address_df['zip'] = address_df['zip'].astype(str).str.zfill(5)\n# Merge dataframes\n# Merge address info with ZIP coordinates\nmerged_df = pd.merge(\n    address_df,\n    zip_latlng_df[['zip', 'lat', 'lng']],\n    how='inner',\n    on='zip'\n)\nprint(f\"Total records after merging with ZIP coordinates: {len(merged_df)}\")",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "merged_df",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "merged_df = pd.merge(\n    address_df,\n    zip_latlng_df[['zip', 'lat', 'lng']],\n    how='inner',\n    on='zip'\n)\nprint(f\"Total records after merging with ZIP coordinates: {len(merged_df)}\")\n# Color palette for each year\nyear_colors = {\n    2015: 'blue',",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "year_colors",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "year_colors = {\n    2015: 'blue',\n    2016: 'green',\n    2017: 'purple',\n    2018: 'orange',\n    2019: 'red',\n    2020: 'pink',\n    2021: 'cadetblue'\n}\n# Create base map",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "m",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "m = folium.Map(location=[merged_df['lat'].mean(), merged_df['lng'].mean()], zoom_start=5)\n# Create a FeatureGroup for each year\nfor year, color in year_colors.items():\n    year_data = merged_df[merged_df['year'] == year]\n    fg = folium.FeatureGroup(name=f\"{year}\", show=True)\n    cluster = MarkerCluster().add_to(fg)\n#### loop through each row in the year_data DataFrame\n    for _, row in year_data.iterrows():\n        folium.Marker(\n            location=[row['lat'], row['lng']],",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "files",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "files = {\n    \"2015\": \"2015_CostReport_cleaned.csv\",\n    \"2016\": \"2016_CostReport_cleaned.csv\",\n    \"2017\": \"2017_CostReport_cleaned.csv\",\n    \"2018\": \"2018_CostReport_cleaned.csv\",\n    \"2019\": \"2019_CostReport_cleaned.csv\",\n    \"2020\": \"2020_CostReport_cleaned.csv\",\n    \"2021\": \"2021_CostReport_cleaned.csv\"\n}\n# List to store dataframes for each year",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "all_dataframes",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "all_dataframes = []\n# Loop through each file, read it, add a 'Year' column, and append to the list\nfor year, path in files.items():\n    df = pd.read_csv(path, low_memory=False)  # read CSV file\n    df['Year'] = int(year)  # add a 'Year' column for reference\n    all_dataframes.append(df)  # append the dataframe to the list\n# Combine all yearly dataframes into one single dataframe\nmerged_df = pd.concat(all_dataframes, ignore_index=True)\n# Selecting relevant features for the model (commented out features are excluded)\nX = merged_df[[",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "merged_df",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "merged_df = pd.concat(all_dataframes, ignore_index=True)\n# Selecting relevant features for the model (commented out features are excluded)\nX = merged_df[[\n    # 'cash_on_hand_and_in_banks',\n    # 'overhead_non_salary_costs',\n    # 'total_fund_balances',\n    'gross_revenue',\n    'total_income',\n    'total_costs',\n    'total_current_assets',",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "X",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "X = merged_df[[\n    # 'cash_on_hand_and_in_banks',\n    # 'overhead_non_salary_costs',\n    # 'total_fund_balances',\n    'gross_revenue',\n    'total_income',\n    'total_costs',\n    'total_current_assets',\n    'total_current_liabilities',\n    'total_liabilities',",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "y = merged_df['net_income']\n# Split data into training and testing sets (80% train, 20% test)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Standardize the features (zero mean, unit variance)\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)  # fit on training data\nX_test = scaler.transform(X_test)  # transform test data using the same scaler\n# Define parameter grid for hyperparameter tuning\nparam_grid = {\n    'n_estimators': [100, 200, 300],  # number of trees",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "scaler",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)  # fit on training data\nX_test = scaler.transform(X_test)  # transform test data using the same scaler\n# Define parameter grid for hyperparameter tuning\nparam_grid = {\n    'n_estimators': [100, 200, 300],  # number of trees\n    'learning_rate': [0.05, 0.1, 0.2],  # step size shrinkage\n    'max_depth': [3, 4, 5]  # maximum depth of trees\n}\n# Use GridSearchCV to find the best combination of parameters",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "X_train",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "X_train = scaler.fit_transform(X_train)  # fit on training data\nX_test = scaler.transform(X_test)  # transform test data using the same scaler\n# Define parameter grid for hyperparameter tuning\nparam_grid = {\n    'n_estimators': [100, 200, 300],  # number of trees\n    'learning_rate': [0.05, 0.1, 0.2],  # step size shrinkage\n    'max_depth': [3, 4, 5]  # maximum depth of trees\n}\n# Use GridSearchCV to find the best combination of parameters\ngrid_search = GridSearchCV(xgb.XGBRegressor(random_state=42), param_grid, cv=5, scoring='r2')",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "X_test",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "X_test = scaler.transform(X_test)  # transform test data using the same scaler\n# Define parameter grid for hyperparameter tuning\nparam_grid = {\n    'n_estimators': [100, 200, 300],  # number of trees\n    'learning_rate': [0.05, 0.1, 0.2],  # step size shrinkage\n    'max_depth': [3, 4, 5]  # maximum depth of trees\n}\n# Use GridSearchCV to find the best combination of parameters\ngrid_search = GridSearchCV(xgb.XGBRegressor(random_state=42), param_grid, cv=5, scoring='r2')\ngrid_search.fit(X_train, y_train)  # train with cross-validation",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "param_grid",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "param_grid = {\n    'n_estimators': [100, 200, 300],  # number of trees\n    'learning_rate': [0.05, 0.1, 0.2],  # step size shrinkage\n    'max_depth': [3, 4, 5]  # maximum depth of trees\n}\n# Use GridSearchCV to find the best combination of parameters\ngrid_search = GridSearchCV(xgb.XGBRegressor(random_state=42), param_grid, cv=5, scoring='r2')\ngrid_search.fit(X_train, y_train)  # train with cross-validation\n# Retrieve and print the best hyperparameters found\nbest_params = grid_search.best_params_",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "grid_search",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "grid_search = GridSearchCV(xgb.XGBRegressor(random_state=42), param_grid, cv=5, scoring='r2')\ngrid_search.fit(X_train, y_train)  # train with cross-validation\n# Retrieve and print the best hyperparameters found\nbest_params = grid_search.best_params_\nprint(\"Best Parameters:\", best_params)\n# Train final model using the best parameters from GridSearch\nmodel = xgb.XGBRegressor(**best_params, random_state=42)\nmodel.fit(X_train, y_train)\n# Make predictions on the test set\ny_pred = model.predict(X_test)",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "best_params",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "best_params = grid_search.best_params_\nprint(\"Best Parameters:\", best_params)\n# Train final model using the best parameters from GridSearch\nmodel = xgb.XGBRegressor(**best_params, random_state=42)\nmodel.fit(X_train, y_train)\n# Make predictions on the test set\ny_pred = model.predict(X_test)\n# Evaluate the model using common regression metrics\nmse = mean_squared_error(y_test, y_pred)  # mean squared error\nr2 = r2_score(y_test, y_pred)  # R-squared score",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "model = xgb.XGBRegressor(**best_params, random_state=42)\nmodel.fit(X_train, y_train)\n# Make predictions on the test set\ny_pred = model.predict(X_test)\n# Evaluate the model using common regression metrics\nmse = mean_squared_error(y_test, y_pred)  # mean squared error\nr2 = r2_score(y_test, y_pred)  # R-squared score\nrmse = np.sqrt(mse)  # root mean squared error\n# Print evaluation results\nprint(f\"\\nFinal RMSE on Test Set: {rmse:.2f}\")",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "y_pred",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "y_pred = model.predict(X_test)\n# Evaluate the model using common regression metrics\nmse = mean_squared_error(y_test, y_pred)  # mean squared error\nr2 = r2_score(y_test, y_pred)  # R-squared score\nrmse = np.sqrt(mse)  # root mean squared error\n# Print evaluation results\nprint(f\"\\nFinal RMSE on Test Set: {rmse:.2f}\")\nprint(f\"Mean Squared Error: {mse:.4f}\")\nprint(f\"R^2 Score: {r2:.4f}\")\n# # Feature importance visualization (currently commented out)",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "mse",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "mse = mean_squared_error(y_test, y_pred)  # mean squared error\nr2 = r2_score(y_test, y_pred)  # R-squared score\nrmse = np.sqrt(mse)  # root mean squared error\n# Print evaluation results\nprint(f\"\\nFinal RMSE on Test Set: {rmse:.2f}\")\nprint(f\"Mean Squared Error: {mse:.4f}\")\nprint(f\"R^2 Score: {r2:.4f}\")\n# # Feature importance visualization (currently commented out)\n# feature_importance = model.feature_importances_\n# sorted_idx = np.argsort(feature_importance)[::-1]",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "r2",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "r2 = r2_score(y_test, y_pred)  # R-squared score\nrmse = np.sqrt(mse)  # root mean squared error\n# Print evaluation results\nprint(f\"\\nFinal RMSE on Test Set: {rmse:.2f}\")\nprint(f\"Mean Squared Error: {mse:.4f}\")\nprint(f\"R^2 Score: {r2:.4f}\")\n# # Feature importance visualization (currently commented out)\n# feature_importance = model.feature_importances_\n# sorted_idx = np.argsort(feature_importance)[::-1]\n# plt.figure(figsize=(10, 6))",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "rmse",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "rmse = np.sqrt(mse)  # root mean squared error\n# Print evaluation results\nprint(f\"\\nFinal RMSE on Test Set: {rmse:.2f}\")\nprint(f\"Mean Squared Error: {mse:.4f}\")\nprint(f\"R^2 Score: {r2:.4f}\")\n# # Feature importance visualization (currently commented out)\n# feature_importance = model.feature_importances_\n# sorted_idx = np.argsort(feature_importance)[::-1]\n# plt.figure(figsize=(10, 6))\n# plt.barh(np.array(X.columns)[sorted_idx], feature_importance[sorted_idx])",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "files",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "files = {\n    \"2015\": \"2015_CostReport_cleaned.csv\",\n    \"2016\": \"2016_CostReport_cleaned.csv\",\n    \"2017\": \"2017_CostReport_cleaned.csv\",\n    \"2018\": \"2018_CostReport_cleaned.csv\",\n    \"2019\": \"2019_CostReport_cleaned.csv\",\n    \"2020\": \"2020_CostReport_cleaned.csv\",\n    \"2021\": \"2021_CostReport_cleaned.csv\"\n}\n# List to store dataframes for each year",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "all_dataframes",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "all_dataframes = []\n# Loop through each file, read it, add a 'Year' column, and append to the list\nfor year, path in files.items():\n    df = pd.read_csv(path, low_memory=False)  # read CSV file\n    df['Year'] = int(year)  # add a 'Year' column for reference\n    all_dataframes.append(df)  # append the dataframe to the list\n# Combine all yearly dataframes into one single dataframe\nmerged_df = pd.concat(all_dataframes, ignore_index=True)\n# Selecting relevant features for the model (commented out features are excluded)\nX = merged_df[[",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "merged_df",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "merged_df = pd.concat(all_dataframes, ignore_index=True)\n# Selecting relevant features for the model (commented out features are excluded)\nX = merged_df[[\n    # 'cash_on_hand_and_in_banks',\n    # 'overhead_non_salary_costs',\n    # 'total_fund_balances',\n    'gross_revenue',\n    'total_income',\n    'total_costs',\n    'total_current_assets',",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "X",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "X = merged_df[[\n    # 'cash_on_hand_and_in_banks',\n    # 'overhead_non_salary_costs',\n    # 'total_fund_balances',\n    'gross_revenue',\n    'total_income',\n    'total_costs',\n    'total_current_assets',\n    'total_current_liabilities',\n    'total_liabilities',",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "y = merged_df['net_income']\n# Split data into training and testing sets (80% train, 20% test)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Standardize the features (zero mean, unit variance)\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)  # fit on training data\nX_test = scaler.transform(X_test)  # transform test data using the same scaler\n# Define parameter grid for hyperparameter tuning\nparam_grid = {\n    'n_estimators': [100, 200, 300],  # number of trees",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "scaler",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)  # fit on training data\nX_test = scaler.transform(X_test)  # transform test data using the same scaler\n# Define parameter grid for hyperparameter tuning\nparam_grid = {\n    'n_estimators': [100, 200, 300],  # number of trees\n    'learning_rate': [0.05, 0.1, 0.2],  # step size shrinkage\n    'max_depth': [3, 4, 5]  # maximum depth of trees\n}\n# Use GridSearchCV to find the best combination of parameters",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "X_train",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "X_train = scaler.fit_transform(X_train)  # fit on training data\nX_test = scaler.transform(X_test)  # transform test data using the same scaler\n# Define parameter grid for hyperparameter tuning\nparam_grid = {\n    'n_estimators': [100, 200, 300],  # number of trees\n    'learning_rate': [0.05, 0.1, 0.2],  # step size shrinkage\n    'max_depth': [3, 4, 5]  # maximum depth of trees\n}\n# Use GridSearchCV to find the best combination of parameters\ngrid_search = GridSearchCV(xgb.XGBRegressor(random_state=42), param_grid, cv=5, scoring='r2')",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "X_test",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "X_test = scaler.transform(X_test)  # transform test data using the same scaler\n# Define parameter grid for hyperparameter tuning\nparam_grid = {\n    'n_estimators': [100, 200, 300],  # number of trees\n    'learning_rate': [0.05, 0.1, 0.2],  # step size shrinkage\n    'max_depth': [3, 4, 5]  # maximum depth of trees\n}\n# Use GridSearchCV to find the best combination of parameters\ngrid_search = GridSearchCV(xgb.XGBRegressor(random_state=42), param_grid, cv=5, scoring='r2')\ngrid_search.fit(X_train, y_train)  # train with cross-validation",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "param_grid",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "param_grid = {\n    'n_estimators': [100, 200, 300],  # number of trees\n    'learning_rate': [0.05, 0.1, 0.2],  # step size shrinkage\n    'max_depth': [3, 4, 5]  # maximum depth of trees\n}\n# Use GridSearchCV to find the best combination of parameters\ngrid_search = GridSearchCV(xgb.XGBRegressor(random_state=42), param_grid, cv=5, scoring='r2')\ngrid_search.fit(X_train, y_train)  # train with cross-validation\n# Retrieve and print the best hyperparameters found\nbest_params = grid_search.best_params_",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "grid_search",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "grid_search = GridSearchCV(xgb.XGBRegressor(random_state=42), param_grid, cv=5, scoring='r2')\ngrid_search.fit(X_train, y_train)  # train with cross-validation\n# Retrieve and print the best hyperparameters found\nbest_params = grid_search.best_params_\nprint(\"Best Parameters:\", best_params)\n# Train final model using the best parameters from GridSearch\nmodel = xgb.XGBRegressor(**best_params, random_state=42)\nmodel.fit(X_train, y_train)\n# Make predictions on the test set\ny_pred = model.predict(X_test)",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "best_params",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "best_params = grid_search.best_params_\nprint(\"Best Parameters:\", best_params)\n# Train final model using the best parameters from GridSearch\nmodel = xgb.XGBRegressor(**best_params, random_state=42)\nmodel.fit(X_train, y_train)\n# Make predictions on the test set\ny_pred = model.predict(X_test)\n# Evaluate the model using common regression metrics\nmse = mean_squared_error(y_test, y_pred)  # mean squared error\nr2 = r2_score(y_test, y_pred)  # R-squared score",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "model = xgb.XGBRegressor(**best_params, random_state=42)\nmodel.fit(X_train, y_train)\n# Make predictions on the test set\ny_pred = model.predict(X_test)\n# Evaluate the model using common regression metrics\nmse = mean_squared_error(y_test, y_pred)  # mean squared error\nr2 = r2_score(y_test, y_pred)  # R-squared score\nrmse = np.sqrt(mse)  # root mean squared error\n# Print evaluation results\nprint(f\"\\nFinal RMSE on Test Set: {rmse:.2f}\")",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "y_pred",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "y_pred = model.predict(X_test)\n# Evaluate the model using common regression metrics\nmse = mean_squared_error(y_test, y_pred)  # mean squared error\nr2 = r2_score(y_test, y_pred)  # R-squared score\nrmse = np.sqrt(mse)  # root mean squared error\n# Print evaluation results\nprint(f\"\\nFinal RMSE on Test Set: {rmse:.2f}\")\nprint(f\"Mean Squared Error: {mse:.4f}\")\nprint(f\"R^2 Score: {r2:.4f}\")\n# # Feature importance visualization (currently commented out)",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "mse",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "mse = mean_squared_error(y_test, y_pred)  # mean squared error\nr2 = r2_score(y_test, y_pred)  # R-squared score\nrmse = np.sqrt(mse)  # root mean squared error\n# Print evaluation results\nprint(f\"\\nFinal RMSE on Test Set: {rmse:.2f}\")\nprint(f\"Mean Squared Error: {mse:.4f}\")\nprint(f\"R^2 Score: {r2:.4f}\")\n# # Feature importance visualization (currently commented out)\n# feature_importance = model.feature_importances_\n# sorted_idx = np.argsort(feature_importance)[::-1]",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "r2",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "r2 = r2_score(y_test, y_pred)  # R-squared score\nrmse = np.sqrt(mse)  # root mean squared error\n# Print evaluation results\nprint(f\"\\nFinal RMSE on Test Set: {rmse:.2f}\")\nprint(f\"Mean Squared Error: {mse:.4f}\")\nprint(f\"R^2 Score: {r2:.4f}\")\n# # Feature importance visualization (currently commented out)\n# feature_importance = model.feature_importances_\n# sorted_idx = np.argsort(feature_importance)[::-1]\n# plt.figure(figsize=(10, 6))",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "rmse",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "rmse = np.sqrt(mse)  # root mean squared error\n# Print evaluation results\nprint(f\"\\nFinal RMSE on Test Set: {rmse:.2f}\")\nprint(f\"Mean Squared Error: {mse:.4f}\")\nprint(f\"R^2 Score: {r2:.4f}\")\n# # Feature importance visualization (currently commented out)\n# feature_importance = model.feature_importances_\n# sorted_idx = np.argsort(feature_importance)[::-1]\n# plt.figure(figsize=(10, 6))\n# plt.barh(np.array(X.columns)[sorted_idx], feature_importance[sorted_idx])",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "df = pd.read_csv(\"Merged_2015_Data.csv\")\n# Clean target variable\ndf[\"WEIGHTED_ALL_CYCLES_SCORE\"] = pd.to_numeric(df[\"WEIGHTED_ALL_CYCLES_SCORE\"], errors=\"coerce\")\ndf = df.dropna(subset=[\"WEIGHTED_ALL_CYCLES_SCORE\"])\n# Define features\nfeatures = [\n    \"incident_cnt\", \"cmplnt_cnt\", \"FINE_TOT\", \"TOT_PENLTY_CNT\",\n    \"deficiency_count\", \"total_fines\", \"total_payden_days\",\n    \"avg_quality_measure\", \"total_fund_balances\", \"total_liabilities\", \"total_other_assets\"\n]",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "df[\"WEIGHTED_ALL_CYCLES_SCORE\"]",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "df[\"WEIGHTED_ALL_CYCLES_SCORE\"] = pd.to_numeric(df[\"WEIGHTED_ALL_CYCLES_SCORE\"], errors=\"coerce\")\ndf = df.dropna(subset=[\"WEIGHTED_ALL_CYCLES_SCORE\"])\n# Define features\nfeatures = [\n    \"incident_cnt\", \"cmplnt_cnt\", \"FINE_TOT\", \"TOT_PENLTY_CNT\",\n    \"deficiency_count\", \"total_fines\", \"total_payden_days\",\n    \"avg_quality_measure\", \"total_fund_balances\", \"total_liabilities\", \"total_other_assets\"\n]\ndf = df.dropna(subset=features)\nX = df[features]",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "df = df.dropna(subset=[\"WEIGHTED_ALL_CYCLES_SCORE\"])\n# Define features\nfeatures = [\n    \"incident_cnt\", \"cmplnt_cnt\", \"FINE_TOT\", \"TOT_PENLTY_CNT\",\n    \"deficiency_count\", \"total_fines\", \"total_payden_days\",\n    \"avg_quality_measure\", \"total_fund_balances\", \"total_liabilities\", \"total_other_assets\"\n]\ndf = df.dropna(subset=features)\nX = df[features]\ny = df[\"WEIGHTED_ALL_CYCLES_SCORE\"]",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "features",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "features = [\n    \"incident_cnt\", \"cmplnt_cnt\", \"FINE_TOT\", \"TOT_PENLTY_CNT\",\n    \"deficiency_count\", \"total_fines\", \"total_payden_days\",\n    \"avg_quality_measure\", \"total_fund_balances\", \"total_liabilities\", \"total_other_assets\"\n]\ndf = df.dropna(subset=features)\nX = df[features]\ny = df[\"WEIGHTED_ALL_CYCLES_SCORE\"]\n# Train/test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "df = df.dropna(subset=features)\nX = df[features]\ny = df[\"WEIGHTED_ALL_CYCLES_SCORE\"]\n# Train/test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Train model\nmodel = RandomForestRegressor(random_state=42)\nmodel.fit(X_train, y_train)\n# Predict and evaluate\ny_pred = model.predict(X_test)",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "X",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "X = df[features]\ny = df[\"WEIGHTED_ALL_CYCLES_SCORE\"]\n# Train/test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Train model\nmodel = RandomForestRegressor(random_state=42)\nmodel.fit(X_train, y_train)\n# Predict and evaluate\ny_pred = model.predict(X_test)\nr2 = r2_score(y_test, y_pred)",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "y = df[\"WEIGHTED_ALL_CYCLES_SCORE\"]\n# Train/test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Train model\nmodel = RandomForestRegressor(random_state=42)\nmodel.fit(X_train, y_train)\n# Predict and evaluate\ny_pred = model.predict(X_test)\nr2 = r2_score(y_test, y_pred)\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "model = RandomForestRegressor(random_state=42)\nmodel.fit(X_train, y_train)\n# Predict and evaluate\ny_pred = model.predict(X_test)\nr2 = r2_score(y_test, y_pred)\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\n# Output results\nprint(f\"R²: {r2:.3f}, RMSE: {rmse:.2f}\")\n# Plot feature importances\nimportances = pd.Series(model.feature_importances_, index=features)",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "y_pred",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "y_pred = model.predict(X_test)\nr2 = r2_score(y_test, y_pred)\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\n# Output results\nprint(f\"R²: {r2:.3f}, RMSE: {rmse:.2f}\")\n# Plot feature importances\nimportances = pd.Series(model.feature_importances_, index=features)\nimportances.sort_values().plot(kind=\"barh\", figsize=(10, 6), title=\"Feature Importance (2015)\")\nplt.tight_layout()\nplt.show()",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "r2",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "r2 = r2_score(y_test, y_pred)\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\n# Output results\nprint(f\"R²: {r2:.3f}, RMSE: {rmse:.2f}\")\n# Plot feature importances\nimportances = pd.Series(model.feature_importances_, index=features)\nimportances.sort_values().plot(kind=\"barh\", figsize=(10, 6), title=\"Feature Importance (2015)\")\nplt.tight_layout()\nplt.show()\n#############################",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "rmse",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n# Output results\nprint(f\"R²: {r2:.3f}, RMSE: {rmse:.2f}\")\n# Plot feature importances\nimportances = pd.Series(model.feature_importances_, index=features)\nimportances.sort_values().plot(kind=\"barh\", figsize=(10, 6), title=\"Feature Importance (2015)\")\nplt.tight_layout()\nplt.show()\n#############################\n##### Data Merging and Exporting #####",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "importances",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "importances = pd.Series(model.feature_importances_, index=features)\nimportances.sort_values().plot(kind=\"barh\", figsize=(10, 6), title=\"Feature Importance (2015)\")\nplt.tight_layout()\nplt.show()\n#############################\n##### Data Merging and Exporting #####\n# Importing required libraries\nimport pandas as pd\n# Load CSV files from your local directory\nprovider_df = pd.read_csv(\"Cleaned_ProviderInfo_2015.csv\", dtype={\"provnum\": str})",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "provider_df",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "provider_df = pd.read_csv(\"Cleaned_ProviderInfo_2015.csv\", dtype={\"provnum\": str})\ncost_df = pd.read_csv(\"2015_CostReport_cleaned.csv\", dtype={\"provider_ccn\": str})\ndeficiency_df = pd.read_csv(\"HealthDeficiencies_2015.csv\", encoding=\"latin1\", dtype={\"provnum\": str})\npenalty_df = pd.read_csv(\"Penalties_2015_Clean.csv\", dtype={\"provnum\": str})\nquality_df = pd.read_csv(\"QualityMsrMDS_2015_Cleaned.csv\", dtype={\"provnum\": str})\n# Standardize provider ID format\nprovider_df[\"provnum\"] = provider_df[\"provnum\"].str.zfill(6)\ncost_df[\"provider_ccn\"] = cost_df[\"provider_ccn\"].str.zfill(6)\ndeficiency_df[\"provnum\"] = deficiency_df[\"provnum\"].str.zfill(6)\npenalty_df[\"provnum\"] = penalty_df[\"provnum\"].str.zfill(6)",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "cost_df",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "cost_df = pd.read_csv(\"2015_CostReport_cleaned.csv\", dtype={\"provider_ccn\": str})\ndeficiency_df = pd.read_csv(\"HealthDeficiencies_2015.csv\", encoding=\"latin1\", dtype={\"provnum\": str})\npenalty_df = pd.read_csv(\"Penalties_2015_Clean.csv\", dtype={\"provnum\": str})\nquality_df = pd.read_csv(\"QualityMsrMDS_2015_Cleaned.csv\", dtype={\"provnum\": str})\n# Standardize provider ID format\nprovider_df[\"provnum\"] = provider_df[\"provnum\"].str.zfill(6)\ncost_df[\"provider_ccn\"] = cost_df[\"provider_ccn\"].str.zfill(6)\ndeficiency_df[\"provnum\"] = deficiency_df[\"provnum\"].str.zfill(6)\npenalty_df[\"provnum\"] = penalty_df[\"provnum\"].str.zfill(6)\nquality_df[\"provnum\"] = quality_df[\"provnum\"].str.zfill(6)",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "deficiency_df",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "deficiency_df = pd.read_csv(\"HealthDeficiencies_2015.csv\", encoding=\"latin1\", dtype={\"provnum\": str})\npenalty_df = pd.read_csv(\"Penalties_2015_Clean.csv\", dtype={\"provnum\": str})\nquality_df = pd.read_csv(\"QualityMsrMDS_2015_Cleaned.csv\", dtype={\"provnum\": str})\n# Standardize provider ID format\nprovider_df[\"provnum\"] = provider_df[\"provnum\"].str.zfill(6)\ncost_df[\"provider_ccn\"] = cost_df[\"provider_ccn\"].str.zfill(6)\ndeficiency_df[\"provnum\"] = deficiency_df[\"provnum\"].str.zfill(6)\npenalty_df[\"provnum\"] = penalty_df[\"provnum\"].str.zfill(6)\nquality_df[\"provnum\"] = quality_df[\"provnum\"].str.zfill(6)\n# Aggregate deficiency counts",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "penalty_df",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "penalty_df = pd.read_csv(\"Penalties_2015_Clean.csv\", dtype={\"provnum\": str})\nquality_df = pd.read_csv(\"QualityMsrMDS_2015_Cleaned.csv\", dtype={\"provnum\": str})\n# Standardize provider ID format\nprovider_df[\"provnum\"] = provider_df[\"provnum\"].str.zfill(6)\ncost_df[\"provider_ccn\"] = cost_df[\"provider_ccn\"].str.zfill(6)\ndeficiency_df[\"provnum\"] = deficiency_df[\"provnum\"].str.zfill(6)\npenalty_df[\"provnum\"] = penalty_df[\"provnum\"].str.zfill(6)\nquality_df[\"provnum\"] = quality_df[\"provnum\"].str.zfill(6)\n# Aggregate deficiency counts\ndeficiency_counts = deficiency_df.groupby(\"provnum\").size().reset_index(name=\"deficiency_count\")",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "quality_df",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "quality_df = pd.read_csv(\"QualityMsrMDS_2015_Cleaned.csv\", dtype={\"provnum\": str})\n# Standardize provider ID format\nprovider_df[\"provnum\"] = provider_df[\"provnum\"].str.zfill(6)\ncost_df[\"provider_ccn\"] = cost_df[\"provider_ccn\"].str.zfill(6)\ndeficiency_df[\"provnum\"] = deficiency_df[\"provnum\"].str.zfill(6)\npenalty_df[\"provnum\"] = penalty_df[\"provnum\"].str.zfill(6)\nquality_df[\"provnum\"] = quality_df[\"provnum\"].str.zfill(6)\n# Aggregate deficiency counts\ndeficiency_counts = deficiency_df.groupby(\"provnum\").size().reset_index(name=\"deficiency_count\")\n# Summarize penalties",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "provider_df[\"provnum\"]",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "provider_df[\"provnum\"] = provider_df[\"provnum\"].str.zfill(6)\ncost_df[\"provider_ccn\"] = cost_df[\"provider_ccn\"].str.zfill(6)\ndeficiency_df[\"provnum\"] = deficiency_df[\"provnum\"].str.zfill(6)\npenalty_df[\"provnum\"] = penalty_df[\"provnum\"].str.zfill(6)\nquality_df[\"provnum\"] = quality_df[\"provnum\"].str.zfill(6)\n# Aggregate deficiency counts\ndeficiency_counts = deficiency_df.groupby(\"provnum\").size().reset_index(name=\"deficiency_count\")\n# Summarize penalties\npenalty_summary = penalty_df.groupby(\"provnum\").agg({\n    \"fine_amt\": \"sum\",",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "cost_df[\"provider_ccn\"]",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "cost_df[\"provider_ccn\"] = cost_df[\"provider_ccn\"].str.zfill(6)\ndeficiency_df[\"provnum\"] = deficiency_df[\"provnum\"].str.zfill(6)\npenalty_df[\"provnum\"] = penalty_df[\"provnum\"].str.zfill(6)\nquality_df[\"provnum\"] = quality_df[\"provnum\"].str.zfill(6)\n# Aggregate deficiency counts\ndeficiency_counts = deficiency_df.groupby(\"provnum\").size().reset_index(name=\"deficiency_count\")\n# Summarize penalties\npenalty_summary = penalty_df.groupby(\"provnum\").agg({\n    \"fine_amt\": \"sum\",\n    \"payden_days\": \"sum\"",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "deficiency_df[\"provnum\"]",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "deficiency_df[\"provnum\"] = deficiency_df[\"provnum\"].str.zfill(6)\npenalty_df[\"provnum\"] = penalty_df[\"provnum\"].str.zfill(6)\nquality_df[\"provnum\"] = quality_df[\"provnum\"].str.zfill(6)\n# Aggregate deficiency counts\ndeficiency_counts = deficiency_df.groupby(\"provnum\").size().reset_index(name=\"deficiency_count\")\n# Summarize penalties\npenalty_summary = penalty_df.groupby(\"provnum\").agg({\n    \"fine_amt\": \"sum\",\n    \"payden_days\": \"sum\"\n}).reset_index().rename(columns={\"fine_amt\": \"total_fines\", \"payden_days\": \"total_payden_days\"})",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "penalty_df[\"provnum\"]",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "penalty_df[\"provnum\"] = penalty_df[\"provnum\"].str.zfill(6)\nquality_df[\"provnum\"] = quality_df[\"provnum\"].str.zfill(6)\n# Aggregate deficiency counts\ndeficiency_counts = deficiency_df.groupby(\"provnum\").size().reset_index(name=\"deficiency_count\")\n# Summarize penalties\npenalty_summary = penalty_df.groupby(\"provnum\").agg({\n    \"fine_amt\": \"sum\",\n    \"payden_days\": \"sum\"\n}).reset_index().rename(columns={\"fine_amt\": \"total_fines\", \"payden_days\": \"total_payden_days\"})\n# Average quality measure",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "quality_df[\"provnum\"]",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "quality_df[\"provnum\"] = quality_df[\"provnum\"].str.zfill(6)\n# Aggregate deficiency counts\ndeficiency_counts = deficiency_df.groupby(\"provnum\").size().reset_index(name=\"deficiency_count\")\n# Summarize penalties\npenalty_summary = penalty_df.groupby(\"provnum\").agg({\n    \"fine_amt\": \"sum\",\n    \"payden_days\": \"sum\"\n}).reset_index().rename(columns={\"fine_amt\": \"total_fines\", \"payden_days\": \"total_payden_days\"})\n# Average quality measure\nquality_scores = quality_df.groupby(\"provnum\").agg({",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "deficiency_counts",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "deficiency_counts = deficiency_df.groupby(\"provnum\").size().reset_index(name=\"deficiency_count\")\n# Summarize penalties\npenalty_summary = penalty_df.groupby(\"provnum\").agg({\n    \"fine_amt\": \"sum\",\n    \"payden_days\": \"sum\"\n}).reset_index().rename(columns={\"fine_amt\": \"total_fines\", \"payden_days\": \"total_payden_days\"})\n# Average quality measure\nquality_scores = quality_df.groupby(\"provnum\").agg({\n    \"measure_score_3qtr_avg\": \"mean\"\n}).reset_index().rename(columns={\"measure_score_3qtr_avg\": \"avg_quality_measure\"})",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "penalty_summary",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "penalty_summary = penalty_df.groupby(\"provnum\").agg({\n    \"fine_amt\": \"sum\",\n    \"payden_days\": \"sum\"\n}).reset_index().rename(columns={\"fine_amt\": \"total_fines\", \"payden_days\": \"total_payden_days\"})\n# Average quality measure\nquality_scores = quality_df.groupby(\"provnum\").agg({\n    \"measure_score_3qtr_avg\": \"mean\"\n}).reset_index().rename(columns={\"measure_score_3qtr_avg\": \"avg_quality_measure\"})\n# Select cost variables\ncost_financials = cost_df[[",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "quality_scores",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "quality_scores = quality_df.groupby(\"provnum\").agg({\n    \"measure_score_3qtr_avg\": \"mean\"\n}).reset_index().rename(columns={\"measure_score_3qtr_avg\": \"avg_quality_measure\"})\n# Select cost variables\ncost_financials = cost_df[[\n    \"provider_ccn\", \"total_fund_balances\", \"total_liabilities\", \"total_other_assets\"\n]].rename(columns={\"provider_ccn\": \"provnum\"})\n# Merge all data\nmerged_df = provider_df[[\n    \"provnum\", \"WEIGHTED_ALL_CYCLES_SCORE\", \"incident_cnt\", \"cmplnt_cnt\", \"FINE_TOT\", \"TOT_PENLTY_CNT\"",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "cost_financials",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "cost_financials = cost_df[[\n    \"provider_ccn\", \"total_fund_balances\", \"total_liabilities\", \"total_other_assets\"\n]].rename(columns={\"provider_ccn\": \"provnum\"})\n# Merge all data\nmerged_df = provider_df[[\n    \"provnum\", \"WEIGHTED_ALL_CYCLES_SCORE\", \"incident_cnt\", \"cmplnt_cnt\", \"FINE_TOT\", \"TOT_PENLTY_CNT\"\n]].copy()\nmerged_df = merged_df.merge(deficiency_counts, on=\"provnum\", how=\"left\")\nmerged_df = merged_df.merge(penalty_summary, on=\"provnum\", how=\"left\")\nmerged_df = merged_df.merge(quality_scores, on=\"provnum\", how=\"left\")",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "merged_df",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "merged_df = provider_df[[\n    \"provnum\", \"WEIGHTED_ALL_CYCLES_SCORE\", \"incident_cnt\", \"cmplnt_cnt\", \"FINE_TOT\", \"TOT_PENLTY_CNT\"\n]].copy()\nmerged_df = merged_df.merge(deficiency_counts, on=\"provnum\", how=\"left\")\nmerged_df = merged_df.merge(penalty_summary, on=\"provnum\", how=\"left\")\nmerged_df = merged_df.merge(quality_scores, on=\"provnum\", how=\"left\")\nmerged_df = merged_df.merge(cost_financials, on=\"provnum\", how=\"left\")\n# Convert score to numeric\nmerged_df[\"WEIGHTED_ALL_CYCLES_SCORE\"] = pd.to_numeric(merged_df[\"WEIGHTED_ALL_CYCLES_SCORE\"], errors='coerce')\n# Export to local CSV",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "merged_df",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "merged_df = merged_df.merge(deficiency_counts, on=\"provnum\", how=\"left\")\nmerged_df = merged_df.merge(penalty_summary, on=\"provnum\", how=\"left\")\nmerged_df = merged_df.merge(quality_scores, on=\"provnum\", how=\"left\")\nmerged_df = merged_df.merge(cost_financials, on=\"provnum\", how=\"left\")\n# Convert score to numeric\nmerged_df[\"WEIGHTED_ALL_CYCLES_SCORE\"] = pd.to_numeric(merged_df[\"WEIGHTED_ALL_CYCLES_SCORE\"], errors='coerce')\n# Export to local CSV\nmerged_df.to_csv(\"Merged_2015_Data.csv\", index=False)",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "merged_df",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "merged_df = merged_df.merge(penalty_summary, on=\"provnum\", how=\"left\")\nmerged_df = merged_df.merge(quality_scores, on=\"provnum\", how=\"left\")\nmerged_df = merged_df.merge(cost_financials, on=\"provnum\", how=\"left\")\n# Convert score to numeric\nmerged_df[\"WEIGHTED_ALL_CYCLES_SCORE\"] = pd.to_numeric(merged_df[\"WEIGHTED_ALL_CYCLES_SCORE\"], errors='coerce')\n# Export to local CSV\nmerged_df.to_csv(\"Merged_2015_Data.csv\", index=False)",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "merged_df",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "merged_df = merged_df.merge(quality_scores, on=\"provnum\", how=\"left\")\nmerged_df = merged_df.merge(cost_financials, on=\"provnum\", how=\"left\")\n# Convert score to numeric\nmerged_df[\"WEIGHTED_ALL_CYCLES_SCORE\"] = pd.to_numeric(merged_df[\"WEIGHTED_ALL_CYCLES_SCORE\"], errors='coerce')\n# Export to local CSV\nmerged_df.to_csv(\"Merged_2015_Data.csv\", index=False)",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "merged_df",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "merged_df = merged_df.merge(cost_financials, on=\"provnum\", how=\"left\")\n# Convert score to numeric\nmerged_df[\"WEIGHTED_ALL_CYCLES_SCORE\"] = pd.to_numeric(merged_df[\"WEIGHTED_ALL_CYCLES_SCORE\"], errors='coerce')\n# Export to local CSV\nmerged_df.to_csv(\"Merged_2015_Data.csv\", index=False)",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "merged_df[\"WEIGHTED_ALL_CYCLES_SCORE\"]",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "merged_df[\"WEIGHTED_ALL_CYCLES_SCORE\"] = pd.to_numeric(merged_df[\"WEIGHTED_ALL_CYCLES_SCORE\"], errors='coerce')\n# Export to local CSV\nmerged_df.to_csv(\"Merged_2015_Data.csv\", index=False)",
        "detail": "project",
        "documentation": {}
    }
]