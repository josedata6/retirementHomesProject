[
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "xgboost",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "xgboost",
        "description": "xgboost",
        "detail": "xgboost",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "seaborn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "seaborn",
        "description": "seaborn",
        "detail": "seaborn",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "GridSearchCV",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "GridSearchCV",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "mean_squared_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "r2_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "mean_squared_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "r2_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "glob",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "glob",
        "description": "glob",
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "folium",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "folium",
        "description": "folium",
        "detail": "folium",
        "documentation": {}
    },
    {
        "label": "MarkerCluster",
        "importPath": "folium.plugins",
        "description": "folium.plugins",
        "isExtraImport": true,
        "detail": "folium.plugins",
        "documentation": {}
    },
    {
        "label": "files",
        "kind": 5,
        "importPath": "FINAL Gradient Boost",
        "description": "FINAL Gradient Boost",
        "peekOfCode": "files = {\n    \"2015\": \"2015_CostReport_cleaned.csv\",\n    \"2016\": \"2016_CostReport_cleaned.csv\",\n    \"2017\": \"2017_CostReport_cleaned.csv\",\n    \"2018\": \"2018_CostReport_cleaned.csv\",\n    \"2019\": \"2019_CostReport_cleaned.csv\",\n    \"2020\": \"2020_CostReport_cleaned.csv\",\n    \"2021\": \"2021_CostReport_cleaned.csv\"\n}\nall_dataframes = []",
        "detail": "FINAL Gradient Boost",
        "documentation": {}
    },
    {
        "label": "all_dataframes",
        "kind": 5,
        "importPath": "FINAL Gradient Boost",
        "description": "FINAL Gradient Boost",
        "peekOfCode": "all_dataframes = []\n# Read and merge data\nfor year, path in files.items():\n    df = pd.read_csv(path, low_memory=False)\n    df['Year'] = int(year)\n    all_dataframes.append(df)\nmerged_df = pd.concat(all_dataframes, ignore_index=True)\n# Define features and target\nX = merged_df[[\n    # 'cash_on_hand_and_in_banks',",
        "detail": "FINAL Gradient Boost",
        "documentation": {}
    },
    {
        "label": "merged_df",
        "kind": 5,
        "importPath": "FINAL Gradient Boost",
        "description": "FINAL Gradient Boost",
        "peekOfCode": "merged_df = pd.concat(all_dataframes, ignore_index=True)\n# Define features and target\nX = merged_df[[\n    # 'cash_on_hand_and_in_banks',\n    # 'overhead_non_salary_costs',\n    # 'total_fund_balances',\n    'gross_revenue',\n    'total_income',\n    'total_costs',\n    'total_current_assets',",
        "detail": "FINAL Gradient Boost",
        "documentation": {}
    },
    {
        "label": "X",
        "kind": 5,
        "importPath": "FINAL Gradient Boost",
        "description": "FINAL Gradient Boost",
        "peekOfCode": "X = merged_df[[\n    # 'cash_on_hand_and_in_banks',\n    # 'overhead_non_salary_costs',\n    # 'total_fund_balances',\n    'gross_revenue',\n    'total_income',\n    'total_costs',\n    'total_current_assets',\n    'total_current_liabilities',\n    'total_liabilities',",
        "detail": "FINAL Gradient Boost",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": "FINAL Gradient Boost",
        "description": "FINAL Gradient Boost",
        "peekOfCode": "y = merged_df['net_income']\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Feature scaling for numeric values\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n# Hyperparameter tuning\nparam_grid = {\n    'n_estimators': [100, 200, 300],",
        "detail": "FINAL Gradient Boost",
        "documentation": {}
    },
    {
        "label": "scaler",
        "kind": 5,
        "importPath": "FINAL Gradient Boost",
        "description": "FINAL Gradient Boost",
        "peekOfCode": "scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n# Hyperparameter tuning\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'learning_rate': [0.05, 0.1, 0.2],\n    'max_depth': [3, 4, 5]\n}\ngrid_search = GridSearchCV(xgb.XGBRegressor(random_state=42), param_grid, cv=5, scoring='r2')",
        "detail": "FINAL Gradient Boost",
        "documentation": {}
    },
    {
        "label": "X_train",
        "kind": 5,
        "importPath": "FINAL Gradient Boost",
        "description": "FINAL Gradient Boost",
        "peekOfCode": "X_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n# Hyperparameter tuning\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'learning_rate': [0.05, 0.1, 0.2],\n    'max_depth': [3, 4, 5]\n}\ngrid_search = GridSearchCV(xgb.XGBRegressor(random_state=42), param_grid, cv=5, scoring='r2')\ngrid_search.fit(X_train, y_train)",
        "detail": "FINAL Gradient Boost",
        "documentation": {}
    },
    {
        "label": "X_test",
        "kind": 5,
        "importPath": "FINAL Gradient Boost",
        "description": "FINAL Gradient Boost",
        "peekOfCode": "X_test = scaler.transform(X_test)\n# Hyperparameter tuning\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'learning_rate': [0.05, 0.1, 0.2],\n    'max_depth': [3, 4, 5]\n}\ngrid_search = GridSearchCV(xgb.XGBRegressor(random_state=42), param_grid, cv=5, scoring='r2')\ngrid_search.fit(X_train, y_train)\n# Best model from GridSearch",
        "detail": "FINAL Gradient Boost",
        "documentation": {}
    },
    {
        "label": "param_grid",
        "kind": 5,
        "importPath": "FINAL Gradient Boost",
        "description": "FINAL Gradient Boost",
        "peekOfCode": "param_grid = {\n    'n_estimators': [100, 200, 300],\n    'learning_rate': [0.05, 0.1, 0.2],\n    'max_depth': [3, 4, 5]\n}\ngrid_search = GridSearchCV(xgb.XGBRegressor(random_state=42), param_grid, cv=5, scoring='r2')\ngrid_search.fit(X_train, y_train)\n# Best model from GridSearch\nbest_params = grid_search.best_params_\nprint(\"Best Parameters:\", best_params)",
        "detail": "FINAL Gradient Boost",
        "documentation": {}
    },
    {
        "label": "grid_search",
        "kind": 5,
        "importPath": "FINAL Gradient Boost",
        "description": "FINAL Gradient Boost",
        "peekOfCode": "grid_search = GridSearchCV(xgb.XGBRegressor(random_state=42), param_grid, cv=5, scoring='r2')\ngrid_search.fit(X_train, y_train)\n# Best model from GridSearch\nbest_params = grid_search.best_params_\nprint(\"Best Parameters:\", best_params)\n# Train XGBoost model with best parameters\nmodel = xgb.XGBRegressor(**best_params, random_state=42)\nmodel.fit(X_train, y_train)\n# Predictions and metrics\ny_pred = model.predict(X_test)",
        "detail": "FINAL Gradient Boost",
        "documentation": {}
    },
    {
        "label": "best_params",
        "kind": 5,
        "importPath": "FINAL Gradient Boost",
        "description": "FINAL Gradient Boost",
        "peekOfCode": "best_params = grid_search.best_params_\nprint(\"Best Parameters:\", best_params)\n# Train XGBoost model with best parameters\nmodel = xgb.XGBRegressor(**best_params, random_state=42)\nmodel.fit(X_train, y_train)\n# Predictions and metrics\ny_pred = model.predict(X_test)\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\nrmse = np.sqrt(mse)",
        "detail": "FINAL Gradient Boost",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "FINAL Gradient Boost",
        "description": "FINAL Gradient Boost",
        "peekOfCode": "model = xgb.XGBRegressor(**best_params, random_state=42)\nmodel.fit(X_train, y_train)\n# Predictions and metrics\ny_pred = model.predict(X_test)\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\nrmse = np.sqrt(mse)\nprint(f\"\\nFinal RMSE on Test Set: {rmse:.2f}\")\nprint(f\"Mean Squared Error: {mse:.4f}\")\nprint(f\"R^2 Score: {r2:.4f}\")",
        "detail": "FINAL Gradient Boost",
        "documentation": {}
    },
    {
        "label": "y_pred",
        "kind": 5,
        "importPath": "FINAL Gradient Boost",
        "description": "FINAL Gradient Boost",
        "peekOfCode": "y_pred = model.predict(X_test)\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\nrmse = np.sqrt(mse)\nprint(f\"\\nFinal RMSE on Test Set: {rmse:.2f}\")\nprint(f\"Mean Squared Error: {mse:.4f}\")\nprint(f\"R^2 Score: {r2:.4f}\")\n# # Feature importance visualization\n# feature_importance = model.feature_importances_\n# sorted_idx = np.argsort(feature_importance)[::-1]",
        "detail": "FINAL Gradient Boost",
        "documentation": {}
    },
    {
        "label": "mse",
        "kind": 5,
        "importPath": "FINAL Gradient Boost",
        "description": "FINAL Gradient Boost",
        "peekOfCode": "mse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\nrmse = np.sqrt(mse)\nprint(f\"\\nFinal RMSE on Test Set: {rmse:.2f}\")\nprint(f\"Mean Squared Error: {mse:.4f}\")\nprint(f\"R^2 Score: {r2:.4f}\")\n# # Feature importance visualization\n# feature_importance = model.feature_importances_\n# sorted_idx = np.argsort(feature_importance)[::-1]\n# plt.figure(figsize=(10, 6))",
        "detail": "FINAL Gradient Boost",
        "documentation": {}
    },
    {
        "label": "r2",
        "kind": 5,
        "importPath": "FINAL Gradient Boost",
        "description": "FINAL Gradient Boost",
        "peekOfCode": "r2 = r2_score(y_test, y_pred)\nrmse = np.sqrt(mse)\nprint(f\"\\nFinal RMSE on Test Set: {rmse:.2f}\")\nprint(f\"Mean Squared Error: {mse:.4f}\")\nprint(f\"R^2 Score: {r2:.4f}\")\n# # Feature importance visualization\n# feature_importance = model.feature_importances_\n# sorted_idx = np.argsort(feature_importance)[::-1]\n# plt.figure(figsize=(10, 6))\n# plt.barh(np.array(X.columns)[sorted_idx], feature_importance[sorted_idx])",
        "detail": "FINAL Gradient Boost",
        "documentation": {}
    },
    {
        "label": "rmse",
        "kind": 5,
        "importPath": "FINAL Gradient Boost",
        "description": "FINAL Gradient Boost",
        "peekOfCode": "rmse = np.sqrt(mse)\nprint(f\"\\nFinal RMSE on Test Set: {rmse:.2f}\")\nprint(f\"Mean Squared Error: {mse:.4f}\")\nprint(f\"R^2 Score: {r2:.4f}\")\n# # Feature importance visualization\n# feature_importance = model.feature_importances_\n# sorted_idx = np.argsort(feature_importance)[::-1]\n# plt.figure(figsize=(10, 6))\n# plt.barh(np.array(X.columns)[sorted_idx], feature_importance[sorted_idx])\n# plt.xlabel(\"Feature Importance\")",
        "detail": "FINAL Gradient Boost",
        "documentation": {}
    },
    {
        "label": "load_address_info",
        "kind": 2,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "def load_address_info(filepath):\n    ## reads file and loads it into a DataFrame\n    df = pd.read_csv(filepath, encoding='ISO-8859-1', low_memory=False) \n    ## Standardize column names\n    df.columns = df.columns.str.strip().str.lower()\n    ### Extract year from filename\n    year = os.path.basename(filepath).split(\"_\")[1]\n    df['year'] = int(year)\n    ### Check for required columns\n    required_cols = ['address', 'city', 'state', 'zip', 'year']",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "merged_df",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "merged_df = pd.concat(all_dataframes, ignore_index=True)\n# Show the shape or a preview\nprint(\"Merged DataFrame shape:\", merged_df.shape)\nprint(merged_df.head())\n# Check the columns of the merged DataFrame\nprint(merged_df.columns)\n# # Get basic statistics\nprint(merged_df.describe())\n# Yearly average net income\n# # print(merged_df.groupby(\"Year\")['Net_Income'].mean())",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "files",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "files = glob.glob(\"QualityMsrMDS_20*_Cleaned.csv\")\n## Function to load address info\ndef load_address_info(filepath):\n    ## reads file and loads it into a DataFrame\n    df = pd.read_csv(filepath, encoding='ISO-8859-1', low_memory=False) \n    ## Standardize column names\n    df.columns = df.columns.str.strip().str.lower()\n    ### Extract year from filename\n    year = os.path.basename(filepath).split(\"_\")[1]\n    df['year'] = int(year)",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "address_df",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "address_df = pd.concat([load_address_info(f) for f in files], ignore_index=True)\naddress_df.drop_duplicates(subset=['address', 'city', 'state', 'zip'], inplace=True)\n# Load ZIP code coordinates\nzip_latlng_df = pd.read_csv('uszips.csv')\nzip_latlng_df['zip'] = zip_latlng_df['zip'].astype(str).str.zfill(5)\naddress_df['zip'] = address_df['zip'].astype(str).str.zfill(5)\n# Merge dataframes\n# Merge address info with ZIP coordinates\nmerged_df = pd.merge(\n    address_df,",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "zip_latlng_df",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "zip_latlng_df = pd.read_csv('uszips.csv')\nzip_latlng_df['zip'] = zip_latlng_df['zip'].astype(str).str.zfill(5)\naddress_df['zip'] = address_df['zip'].astype(str).str.zfill(5)\n# Merge dataframes\n# Merge address info with ZIP coordinates\nmerged_df = pd.merge(\n    address_df,\n    zip_latlng_df[['zip', 'lat', 'lng']],\n    how='inner',\n    on='zip'",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "zip_latlng_df['zip']",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "zip_latlng_df['zip'] = zip_latlng_df['zip'].astype(str).str.zfill(5)\naddress_df['zip'] = address_df['zip'].astype(str).str.zfill(5)\n# Merge dataframes\n# Merge address info with ZIP coordinates\nmerged_df = pd.merge(\n    address_df,\n    zip_latlng_df[['zip', 'lat', 'lng']],\n    how='inner',\n    on='zip'\n)",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "address_df['zip']",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "address_df['zip'] = address_df['zip'].astype(str).str.zfill(5)\n# Merge dataframes\n# Merge address info with ZIP coordinates\nmerged_df = pd.merge(\n    address_df,\n    zip_latlng_df[['zip', 'lat', 'lng']],\n    how='inner',\n    on='zip'\n)\nprint(f\"Total records after merging with ZIP coordinates: {len(merged_df)}\")",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "merged_df",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "merged_df = pd.merge(\n    address_df,\n    zip_latlng_df[['zip', 'lat', 'lng']],\n    how='inner',\n    on='zip'\n)\nprint(f\"Total records after merging with ZIP coordinates: {len(merged_df)}\")\n# Color palette for each year\nyear_colors = {\n    2015: 'blue',",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "year_colors",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "year_colors = {\n    2015: 'blue',\n    2016: 'green',\n    2017: 'purple',\n    2018: 'orange',\n    2019: 'red',\n    2020: 'pink',\n    2021: 'cadetblue'\n}\n# Create base map",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "m",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "m = folium.Map(location=[merged_df['lat'].mean(), merged_df['lng'].mean()], zoom_start=5)\n# Create a FeatureGroup for each year\nfor year, color in year_colors.items():\n    year_data = merged_df[merged_df['year'] == year]\n    fg = folium.FeatureGroup(name=f\"{year}\", show=True)\n    cluster = MarkerCluster().add_to(fg)\n    for _, row in year_data.iterrows():\n        folium.Marker(\n            location=[row['lat'], row['lng']],\n            popup=f\"{row['address']}, {row['city']}, {row['state']} {row['zip']} ({row['year']})\",",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "files",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "files = {\n    \"2015\": \"2015_CostReport_cleaned.csv\",\n    \"2016\": \"2016_CostReport_cleaned.csv\",\n    \"2017\": \"2017_CostReport_cleaned.csv\",\n    \"2018\": \"2018_CostReport_cleaned.csv\",\n    \"2019\": \"2019_CostReport_cleaned.csv\",\n    \"2020\": \"2020_CostReport_cleaned.csv\",\n    \"2021\": \"2021_CostReport_cleaned.csv\"\n}\n# List to store dataframes for each year",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "all_dataframes",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "all_dataframes = []\n# Loop through each file, read it, add a 'Year' column, and append to the list\nfor year, path in files.items():\n    df = pd.read_csv(path, low_memory=False)  # read CSV file\n    df['Year'] = int(year)  # add a 'Year' column for reference\n    all_dataframes.append(df)  # append the dataframe to the list\n# Combine all yearly dataframes into one single dataframe\nmerged_df = pd.concat(all_dataframes, ignore_index=True)\n# Selecting relevant features for the model (commented out features are excluded)\nX = merged_df[[",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "merged_df",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "merged_df = pd.concat(all_dataframes, ignore_index=True)\n# Selecting relevant features for the model (commented out features are excluded)\nX = merged_df[[\n    # 'cash_on_hand_and_in_banks',\n    # 'overhead_non_salary_costs',\n    # 'total_fund_balances',\n    'gross_revenue',\n    'total_income',\n    'total_costs',\n    'total_current_assets',",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "X",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "X = merged_df[[\n    # 'cash_on_hand_and_in_banks',\n    # 'overhead_non_salary_costs',\n    # 'total_fund_balances',\n    'gross_revenue',\n    'total_income',\n    'total_costs',\n    'total_current_assets',\n    'total_current_liabilities',\n    'total_liabilities',",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "y = merged_df['net_income']\n# Split data into training and testing sets (80% train, 20% test)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Standardize the features (zero mean, unit variance)\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)  # fit on training data\nX_test = scaler.transform(X_test)  # transform test data using the same scaler\n# Define parameter grid for hyperparameter tuning\nparam_grid = {\n    'n_estimators': [100, 200, 300],  # number of trees",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "scaler",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)  # fit on training data\nX_test = scaler.transform(X_test)  # transform test data using the same scaler\n# Define parameter grid for hyperparameter tuning\nparam_grid = {\n    'n_estimators': [100, 200, 300],  # number of trees\n    'learning_rate': [0.05, 0.1, 0.2],  # step size shrinkage\n    'max_depth': [3, 4, 5]  # maximum depth of trees\n}\n# Use GridSearchCV to find the best combination of parameters",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "X_train",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "X_train = scaler.fit_transform(X_train)  # fit on training data\nX_test = scaler.transform(X_test)  # transform test data using the same scaler\n# Define parameter grid for hyperparameter tuning\nparam_grid = {\n    'n_estimators': [100, 200, 300],  # number of trees\n    'learning_rate': [0.05, 0.1, 0.2],  # step size shrinkage\n    'max_depth': [3, 4, 5]  # maximum depth of trees\n}\n# Use GridSearchCV to find the best combination of parameters\ngrid_search = GridSearchCV(xgb.XGBRegressor(random_state=42), param_grid, cv=5, scoring='r2')",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "X_test",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "X_test = scaler.transform(X_test)  # transform test data using the same scaler\n# Define parameter grid for hyperparameter tuning\nparam_grid = {\n    'n_estimators': [100, 200, 300],  # number of trees\n    'learning_rate': [0.05, 0.1, 0.2],  # step size shrinkage\n    'max_depth': [3, 4, 5]  # maximum depth of trees\n}\n# Use GridSearchCV to find the best combination of parameters\ngrid_search = GridSearchCV(xgb.XGBRegressor(random_state=42), param_grid, cv=5, scoring='r2')\ngrid_search.fit(X_train, y_train)  # train with cross-validation",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "param_grid",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "param_grid = {\n    'n_estimators': [100, 200, 300],  # number of trees\n    'learning_rate': [0.05, 0.1, 0.2],  # step size shrinkage\n    'max_depth': [3, 4, 5]  # maximum depth of trees\n}\n# Use GridSearchCV to find the best combination of parameters\ngrid_search = GridSearchCV(xgb.XGBRegressor(random_state=42), param_grid, cv=5, scoring='r2')\ngrid_search.fit(X_train, y_train)  # train with cross-validation\n# Retrieve and print the best hyperparameters found\nbest_params = grid_search.best_params_",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "grid_search",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "grid_search = GridSearchCV(xgb.XGBRegressor(random_state=42), param_grid, cv=5, scoring='r2')\ngrid_search.fit(X_train, y_train)  # train with cross-validation\n# Retrieve and print the best hyperparameters found\nbest_params = grid_search.best_params_\nprint(\"Best Parameters:\", best_params)\n# Train final model using the best parameters from GridSearch\nmodel = xgb.XGBRegressor(**best_params, random_state=42)\nmodel.fit(X_train, y_train)\n# Make predictions on the test set\ny_pred = model.predict(X_test)",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "best_params",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "best_params = grid_search.best_params_\nprint(\"Best Parameters:\", best_params)\n# Train final model using the best parameters from GridSearch\nmodel = xgb.XGBRegressor(**best_params, random_state=42)\nmodel.fit(X_train, y_train)\n# Make predictions on the test set\ny_pred = model.predict(X_test)\n# Evaluate the model using common regression metrics\nmse = mean_squared_error(y_test, y_pred)  # mean squared error\nr2 = r2_score(y_test, y_pred)  # R-squared score",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "model = xgb.XGBRegressor(**best_params, random_state=42)\nmodel.fit(X_train, y_train)\n# Make predictions on the test set\ny_pred = model.predict(X_test)\n# Evaluate the model using common regression metrics\nmse = mean_squared_error(y_test, y_pred)  # mean squared error\nr2 = r2_score(y_test, y_pred)  # R-squared score\nrmse = np.sqrt(mse)  # root mean squared error\n# Print evaluation results\nprint(f\"\\nFinal RMSE on Test Set: {rmse:.2f}\")",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "y_pred",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "y_pred = model.predict(X_test)\n# Evaluate the model using common regression metrics\nmse = mean_squared_error(y_test, y_pred)  # mean squared error\nr2 = r2_score(y_test, y_pred)  # R-squared score\nrmse = np.sqrt(mse)  # root mean squared error\n# Print evaluation results\nprint(f\"\\nFinal RMSE on Test Set: {rmse:.2f}\")\nprint(f\"Mean Squared Error: {mse:.4f}\")\nprint(f\"R^2 Score: {r2:.4f}\")\n# # Feature importance visualization (currently commented out)",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "mse",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "mse = mean_squared_error(y_test, y_pred)  # mean squared error\nr2 = r2_score(y_test, y_pred)  # R-squared score\nrmse = np.sqrt(mse)  # root mean squared error\n# Print evaluation results\nprint(f\"\\nFinal RMSE on Test Set: {rmse:.2f}\")\nprint(f\"Mean Squared Error: {mse:.4f}\")\nprint(f\"R^2 Score: {r2:.4f}\")\n# # Feature importance visualization (currently commented out)\n# feature_importance = model.feature_importances_\n# sorted_idx = np.argsort(feature_importance)[::-1]",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "r2",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "r2 = r2_score(y_test, y_pred)  # R-squared score\nrmse = np.sqrt(mse)  # root mean squared error\n# Print evaluation results\nprint(f\"\\nFinal RMSE on Test Set: {rmse:.2f}\")\nprint(f\"Mean Squared Error: {mse:.4f}\")\nprint(f\"R^2 Score: {r2:.4f}\")\n# # Feature importance visualization (currently commented out)\n# feature_importance = model.feature_importances_\n# sorted_idx = np.argsort(feature_importance)[::-1]\n# plt.figure(figsize=(10, 6))",
        "detail": "project",
        "documentation": {}
    },
    {
        "label": "rmse",
        "kind": 5,
        "importPath": "project",
        "description": "project",
        "peekOfCode": "rmse = np.sqrt(mse)  # root mean squared error\n# Print evaluation results\nprint(f\"\\nFinal RMSE on Test Set: {rmse:.2f}\")\nprint(f\"Mean Squared Error: {mse:.4f}\")\nprint(f\"R^2 Score: {r2:.4f}\")\n# # Feature importance visualization (currently commented out)\n# feature_importance = model.feature_importances_\n# sorted_idx = np.argsort(feature_importance)[::-1]\n# plt.figure(figsize=(10, 6))\n# plt.barh(np.array(X.columns)[sorted_idx], feature_importance[sorted_idx])",
        "detail": "project",
        "documentation": {}
    }
]